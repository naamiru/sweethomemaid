{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pyscreeze\n",
    "import uuid\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 識別モデル\n",
    "\n",
    "DATA_DIR = \"./data/piece-images\"\n",
    "TORCH_MODEL_PATH = \"./models/piece_classifier.pth\"\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "idx_to_label = [label for label in sorted(os.listdir(DATA_DIR)) if '.' not in label]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3,),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(9216, len(idx_to_label))\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "def get_model():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(TORCH_MODEL_PATH))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict(images: list[Image.Image]) -> list[str]:\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (0.57665089, 0.5822121, 0.54763596),\n",
    "                (0.18085433, 0.21391266, 0.23309964)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    inputs = torch.stack([transform(image) for image in images])\n",
    "\n",
    "    model = get_model()\n",
    "    output = model(inputs)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    return [idx_to_label[index] for index in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ゲーム画像取り込み\n",
    "\n",
    "# これから取り込む盤面サイズ\n",
    "WIDTH = 9\n",
    "HEIGHT = 9\n",
    "\n",
    "# 9x9 盤面の位置・サイズ\n",
    "LEFT = 812\n",
    "TOP = 515\n",
    "SIZE = 1314\n",
    "UNIT = SIZE // 9\n",
    "\n",
    "def capture(width = WIDTH, height = HEIGHT) -> Image.Image:\n",
    "    board_width = UNIT * min(width, 9)\n",
    "    board_height = int(board_width / width * height)\n",
    "    if height > 9 and height > width:\n",
    "        board_height = UNIT * min(height, 9)\n",
    "        board_width = int(board_height / height * width)\n",
    "    box = (\n",
    "        int(LEFT + SIZE / 2 - board_width / 2),\n",
    "        int(TOP + SIZE / 2 - board_height / 2),\n",
    "        int(LEFT + SIZE / 2 + board_width / 2),\n",
    "        int(TOP + SIZE / 2 + board_height / 2)\n",
    "    )\n",
    "    return pyscreeze.screenshot().crop(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ピース画像保存\n",
    "\n",
    "PIECE_IMAGE_DIR = \"./data/sample-piece-images\"\n",
    "\n",
    "colors = \"\"\"\n",
    "_... ..._\n",
    ".........\n",
    ".........\n",
    ".........\n",
    ".........\n",
    ".........\n",
    ".........\n",
    ".........\n",
    " ... ...\n",
    "\"\"\".strip()\n",
    "\n",
    "positions: list[tuple[int, int]] = []\n",
    "for y, line in enumerate(colors.splitlines()):\n",
    "    for x, token in enumerate(line):\n",
    "        if token != \" \" and token != \"_\":\n",
    "            positions.append((x, y))\n",
    "\n",
    "board_image = capture(WIDTH, HEIGHT)\n",
    "unit = board_image.width / WIDTH\n",
    "piece_images = [\n",
    "    board_image.crop((unit * x, unit * y, unit * (x + 1), unit * (y + 1))).convert('RGB')\n",
    "    for x, y in positions\n",
    "]\n",
    "piece_labels = predict(piece_images)\n",
    "\n",
    "for label, image in zip(piece_labels, piece_images):\n",
    "    os.makedirs(f\"{PIECE_IMAGE_DIR}/{label}\", exist_ok=True)\n",
    "    image.save(f\"{PIECE_IMAGE_DIR}/{label}/{uuid.uuid4()}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# みかん識別モデル\n",
    "\n",
    "MIKAN_DATA_DIR = \"./data/mikans\"\n",
    "MIKAN_TORCH_MODEL_PATH = \"./models/mikan_classifier.pth\"\n",
    "MIKAN_IMAGE_SIZE = 96\n",
    "\n",
    "mikan_idx_to_label = [label for label in sorted(os.listdir(MIKAN_DATA_DIR)) if re.match(r\"\\d+\", label)]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5,),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(10368, len(mikan_idx_to_label))\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "def get_model():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(MIKAN_TORCH_MODEL_PATH))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict(images: list[Image.Image]) -> list[str]:\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((MIKAN_IMAGE_SIZE, MIKAN_IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "               (0.63526792, 0.57570206, 0.48665065),\n",
    "                (0.22508891, 0.20648694, 0.26393888)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    inputs = torch.stack([transform(image) for image in images])\n",
    "\n",
    "    model = get_model()\n",
    "    output = model(inputs)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    return [mikan_idx_to_label[index] for index in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# みかん画像保存\n",
    "\n",
    "MIKAN_IMAGE_DIR = \"./data/mikans/raw\"\n",
    "\n",
    "mikan_1_1 = \"\"\"\n",
    "...   ...\n",
    ".........\n",
    ".........\n",
    " .......\n",
    "  5..5.\n",
    "  .. ..\n",
    " ... ...\n",
    "a......a.\n",
    ".........\n",
    "\"\"\".strip()\n",
    "\n",
    "mikan_1_2 = \"\"\"\n",
    "_.......\n",
    "... . ...\n",
    ".........\n",
    " a....a.\n",
    " ..   ..\n",
    "f... ..f.\n",
    ".........\n",
    " a....a.\n",
    " .......\n",
    "\"\"\".strip()\n",
    "\n",
    "mikan_3 = \"\"\"\n",
    "k. ... k.\n",
    ".. ... ..\n",
    "   ...\n",
    ".........\n",
    ".... ....\n",
    ".........\n",
    "   ...\n",
    "u. ... u.\n",
    ".. ... ..\n",
    "\"\"\".strip()\n",
    "\n",
    "mikan_4_1 = \"\"\"\n",
    "_.......\n",
    ".........\n",
    ".........\n",
    " a. . a.\n",
    " .. . ..\n",
    ".........\n",
    ".........\n",
    "f. ... f.\n",
    ".. ... ..\n",
    "\"\"\".strip()\n",
    "\n",
    "mikan_4_2 = \"\"\"\n",
    ".. ... ..\n",
    ".. ... ..\n",
    "... . ...\n",
    " .......\n",
    "f......f.\n",
    ".........\n",
    "   ...\n",
    " p. . p.\n",
    " .. . ..\n",
    "\"\"\".strip()\n",
    "\n",
    "mikan = mikan_4_2\n",
    "\n",
    "positions: list[tuple[int, int]] = []\n",
    "for y, line in enumerate(mikan.splitlines()):\n",
    "    for x, token in enumerate(line):\n",
    "        if (re.match(r\"[1-9a-z]\", token)):\n",
    "            positions.append((x, y))\n",
    "\n",
    "board_image = capture(9, 9)\n",
    "images = [\n",
    "    board_image.crop((UNIT * x, UNIT * y, UNIT * (x + 2), UNIT * (y + 2))).convert('RGB')\n",
    "    for x, y in positions\n",
    "]\n",
    "labels = predict(images)\n",
    "\n",
    "for label, image in zip(labels, images):\n",
    "    os.makedirs(f\"{MIKAN_IMAGE_DIR}/{label}\", exist_ok=True)\n",
    "    image.save(f\"{MIKAN_IMAGE_DIR}/{label}/{uuid.uuid4()}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Dプリンター画像保存\n",
    "\n",
    "PRINTER_IMAGE_DIR = \"./data/cap-printer\"\n",
    "\n",
    "printer = \"\"\"\n",
    "_... ..._\n",
    ".........\n",
    ".........\n",
    "..5. 5...\n",
    ".... ....\n",
    ".........\n",
    ".........\n",
    "...   ...\n",
    "\"\"\".strip()\n",
    "\n",
    "positions: list[tuple[int, int]] = []\n",
    "for y, line in enumerate(printer.splitlines()):\n",
    "    for x, token in enumerate(line):\n",
    "        if (re.match(r\"[1-9a-z]\", token)):\n",
    "            positions.append((x, y))\n",
    "\n",
    "board_image = capture(9, 8)\n",
    "images = [\n",
    "    board_image.crop((UNIT * x, UNIT * y, UNIT * (x + 2), UNIT * (y + 2))).convert('RGB')\n",
    "    for x, y in positions\n",
    "]\n",
    "\n",
    "for image in images:\n",
    "    os.makedirs(PRINTER_IMAGE_DIR, exist_ok=True)\n",
    "    image.save(f\"{PRINTER_IMAGE_DIR}/{uuid.uuid4()}.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
